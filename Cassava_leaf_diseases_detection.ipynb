{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Install the dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:15:36.667952Z","iopub.status.busy":"2022-04-13T12:15:36.667365Z","iopub.status.idle":"2022-04-13T12:15:46.060537Z","shell.execute_reply":"2022-04-13T12:15:46.059723Z","shell.execute_reply.started":"2022-04-13T12:15:36.667850Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ttach in /Users/gasana/opt/anaconda3/lib/python3.9/site-packages (0.0.3)\n"]}],"source":["!pip install ttach"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:15:46.062198Z","iopub.status.busy":"2022-04-13T12:15:46.061946Z","iopub.status.idle":"2022-04-13T12:15:58.734811Z","shell.execute_reply":"2022-04-13T12:15:58.734012Z","shell.execute_reply.started":"2022-04-13T12:15:46.062164Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/gbaydin/hypergradient-descent.git\n","  Cloning https://github.com/gbaydin/hypergradient-descent.git to /private/var/folders/_b/0hmhgmr17gzcn7j7_yqdx3440000gn/T/pip-req-build-gk81ej_m\n","  Running command git clone --filter=blob:none --quiet https://github.com/gbaydin/hypergradient-descent.git /private/var/folders/_b/0hmhgmr17gzcn7j7_yqdx3440000gn/T/pip-req-build-gk81ej_m\n","  Resolved https://github.com/gbaydin/hypergradient-descent.git to commit 020d6080c4cedfbc88d5cdb7a2a53f92b34c2b16\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: hypergrad\n","  Building wheel for hypergrad (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for hypergrad: filename=hypergrad-0.1-py3-none-any.whl size=8201 sha256=4c6a3e844e81f88d798a1a5835e1b01d4c02edea6b579e7c70a43a3a06117695\n","  Stored in directory: /private/var/folders/_b/0hmhgmr17gzcn7j7_yqdx3440000gn/T/pip-ephem-wheel-cache-g81miazw/wheels/e0/8a/5f/1cc1eb11edbb1d0b970e22f650d1cc6403bbbcb397bcf491d9\n","Successfully built hypergrad\n","Installing collected packages: hypergrad\n","Successfully installed hypergrad-0.1\n"]}],"source":["!pip install git+https://github.com/gbaydin/hypergradient-descent.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:15:58.737496Z","iopub.status.busy":"2022-04-13T12:15:58.736766Z","iopub.status.idle":"2022-04-13T12:16:08.757170Z","shell.execute_reply":"2022-04-13T12:16:08.756291Z","shell.execute_reply.started":"2022-04-13T12:15:58.737452Z"},"trusted":true},"outputs":[],"source":["!pip install pretrainedmodels"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:08.761196Z","iopub.status.busy":"2022-04-13T12:16:08.760966Z","iopub.status.idle":"2022-04-13T12:16:17.979224Z","shell.execute_reply":"2022-04-13T12:16:17.978368Z","shell.execute_reply.started":"2022-04-13T12:16:08.761170Z"},"trusted":true},"outputs":[],"source":["pip install --upgrade efficientnet-pytorch"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:17.980727Z","iopub.status.busy":"2022-04-13T12:16:17.980481Z","iopub.status.idle":"2022-04-13T12:16:29.476228Z","shell.execute_reply":"2022-04-13T12:16:29.475406Z","shell.execute_reply.started":"2022-04-13T12:16:17.980684Z"},"trusted":true},"outputs":[],"source":["!pip install git+https://github.com/gbaydin/hypergradient-descent.git"]},{"cell_type":"markdown","metadata":{},"source":["## Import the dependency"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:29.478302Z","iopub.status.busy":"2022-04-13T12:16:29.478032Z","iopub.status.idle":"2022-04-13T12:16:32.183849Z","shell.execute_reply":"2022-04-13T12:16:32.183128Z","shell.execute_reply.started":"2022-04-13T12:16:29.478266Z"},"trusted":true},"outputs":[],"source":["#Imports\n","import os\n","import sys\n","import glob\n","import torch\n","import torchvision\n","\n","import numpy    as np\n","import datetime as dt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot   as plt\n","\n","from PIL               import Image\n","from torch.utils.data  import Dataset\n","from torch.autograd    import Variable\n","from torch.optim       import lr_scheduler\n","\n","from torch.utils.data  import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torchvision       import transforms, datasets, models\n","from os                import listdir, makedirs, getcwd, remove\n","from os.path           import isfile, join, abspath, exists, isdir, expanduser\n","\n","\n","import pandas as pd\n","\n","from hypergrad import SGDHD, AdamHD\n","\n","import pretrainedmodels\n","\n","from efficientnet_pytorch import EfficientNet\n","\n","import ttach as tta\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Create the hyperparameters"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:32.185390Z","iopub.status.busy":"2022-04-13T12:16:32.185138Z","iopub.status.idle":"2022-04-13T12:16:32.190536Z","shell.execute_reply":"2022-04-13T12:16:32.189872Z","shell.execute_reply.started":"2022-04-13T12:16:32.185357Z"},"trusted":true},"outputs":[],"source":["NAME = \"SUBMISSION\"\n","\n","MODEL_NAME1 = 'se_resnext101_32x4d' # could be fbresnet152 or inceptionresnetv2\n","\n","DIM_1 = 550\n","DIM_2 = 500\n","DIM_TEST_1 = 550\n","DIM_TEST_2 = 500\n","\n","BATCH_SIZE = 8\n","\n","NUM_EPOCHS1 = 10\n","\n","random_seed = 42\n","shuffle_dataset = True\n","validation_split = .1"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:32.192057Z","iopub.status.busy":"2022-04-13T12:16:32.191528Z","iopub.status.idle":"2022-04-13T12:16:32.251476Z","shell.execute_reply":"2022-04-13T12:16:32.250723Z","shell.execute_reply.started":"2022-04-13T12:16:32.192020Z"},"trusted":true},"outputs":[],"source":["# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["## Path to the images"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:32.253176Z","iopub.status.busy":"2022-04-13T12:16:32.252926Z","iopub.status.idle":"2022-04-13T12:16:32.261393Z","shell.execute_reply":"2022-04-13T12:16:32.260484Z","shell.execute_reply.started":"2022-04-13T12:16:32.253142Z"},"trusted":true},"outputs":[],"source":["data_path = \"../input/ammi-2022-convnets/\"\n","train_path = join(data_path, \"train/train\")\n","test_path = join(data_path,\"test/test\")\n","extraimage_path = join(data_path, \"extraimages/extraimages\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create the transform "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:32.263029Z","iopub.status.busy":"2022-04-13T12:16:32.262660Z","iopub.status.idle":"2022-04-13T12:16:32.272182Z","shell.execute_reply":"2022-04-13T12:16:32.271512Z","shell.execute_reply.started":"2022-04-13T12:16:32.262992Z"},"trusted":true},"outputs":[],"source":["# Transformations for both the training and testing data\n","mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]\n","\n","# Do data transforms here, Try many others\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.Resize(DIM_1),\n","                                       transforms.RandomCrop(DIM_2),\n","                                       transforms.RandomHorizontalFlip(0.3),\n","                                       transforms.RandomVerticalFlip(0.3),\n","                                       transforms.ToTensor(),\n","                                       transforms.RandomErasing(0.1),\n","                                       transforms.Normalize(mean=mean, std=std)])\n","\n","test_transforms = transforms.Compose([ transforms.Resize(DIM_TEST_1),\n","                                      transforms.CenterCrop(DIM_TEST_1),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize(mean=mean, std=std)])"]},{"cell_type":"markdown","metadata":{},"source":["## class for preparing the data"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:32.274932Z","iopub.status.busy":"2022-04-13T12:16:32.273505Z","iopub.status.idle":"2022-04-13T12:16:33.483182Z","shell.execute_reply":"2022-04-13T12:16:33.482355Z","shell.execute_reply.started":"2022-04-13T12:16:32.274906Z"},"trusted":true},"outputs":[],"source":["class CassavaDataset(Dataset):\n","    def __init__(self, path, dim, transform=None):\n","        self.classes = os.listdir(path)\n","        self.path = [f\"{path}/{className}\" for className in self.classes]\n","        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n","        self.transform = transform\n","        self.dim = dim\n","\n","        self.targets = []\n","        \n","\n","        files = []\n","        for i, className in enumerate(self.classes):\n","            for fileName in self.file_list[i]:\n","                files.append([i, className, fileName])\n","                self.targets.append(i)\n","                \n","        self.file_list = files\n","        files = None\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        fileName = self.file_list[idx][2]\n","        classCategory = self.file_list[idx][0]\n","        im = Image.open(fileName)\n","        if self.transform:\n","            im = self.transform(im)\n","            \n","        return im.view(3, self.dim, self.dim), classCategory\n","\n","class CassavaTestDataset(Dataset):\n","    def __init__(self, path, dim, transform=None):\n","        self.classes = os.listdir(path)\n","        self.path = [f\"{path}/{className}\" for className in self.classes]\n","        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n","        self.transform = transform\n","        self.indices = []\n","        self.dim=dim\n","\n","        files = []\n","        for i, className in enumerate(self.classes):\n","            for fileName in self.file_list[i]:\n","                files.append([i, className, fileName])\n","                self.indices.append(fileName.split(\"/\")[-1])\n","        self.file_list = files\n","        files = None\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        fileName = self.file_list[idx][2]\n","        index = self.file_list[idx][2]\n","        im = Image.open(fileName)\n","        if self.transform:\n","            im = self.transform(im)\n","            \n","        return im.view(3, self.dim, self.dim), index\n","\n","train_data = CassavaDataset(train_path, dim=DIM_2, transform=train_transforms)\n","test_data = CassavaTestDataset(test_path, dim=DIM_TEST_1, transform=test_transforms)"]},{"cell_type":"markdown","metadata":{},"source":["## Check the class"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.484723Z","iopub.status.busy":"2022-04-13T12:16:33.484448Z","iopub.status.idle":"2022-04-13T12:16:33.492086Z","shell.execute_reply":"2022-04-13T12:16:33.491414Z","shell.execute_reply.started":"2022-04-13T12:16:33.484687Z"},"trusted":true},"outputs":[],"source":["train_data.classes"]},{"cell_type":"markdown","metadata":{},"source":["### Create the dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.496336Z","iopub.status.busy":"2022-04-13T12:16:33.495895Z","iopub.status.idle":"2022-04-13T12:16:33.503167Z","shell.execute_reply":"2022-04-13T12:16:33.502483Z","shell.execute_reply.started":"2022-04-13T12:16:33.496301Z"},"trusted":true},"outputs":[],"source":["# Creating data indices for training and validation splits:\n","dataset_size = len(train_data)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","\n","if shuffle_dataset :\n","    np.random.seed(random_seed)\n","    np.random.shuffle(indices)\n","\n","train_indices, val_indices = indices[split:], indices[:split]"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.504737Z","iopub.status.busy":"2022-04-13T12:16:33.504373Z","iopub.status.idle":"2022-04-13T12:16:33.512158Z","shell.execute_reply":"2022-04-13T12:16:33.511262Z","shell.execute_reply.started":"2022-04-13T12:16:33.504703Z"},"trusted":true},"outputs":[],"source":["train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler = SubsetRandomSampler(val_indices)"]},{"cell_type":"markdown","metadata":{},"source":["## Load the image dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.513834Z","iopub.status.busy":"2022-04-13T12:16:33.513493Z","iopub.status.idle":"2022-04-13T12:16:33.521599Z","shell.execute_reply":"2022-04-13T12:16:33.520838Z","shell.execute_reply.started":"2022-04-13T12:16:33.513798Z"},"trusted":true},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n","                                             sampler=train_sampler)\n","\n","valid_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n","                                             sampler=valid_sampler)\n","\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{},"source":["## Training and testing the model"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.524119Z","iopub.status.busy":"2022-04-13T12:16:33.523928Z","iopub.status.idle":"2022-04-13T12:16:33.544145Z","shell.execute_reply":"2022-04-13T12:16:33.543104Z","shell.execute_reply.started":"2022-04-13T12:16:33.524097Z"},"trusted":true},"outputs":[],"source":["def test(model, data_loader):\n","    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n","    # Make sure the model is in evaluation mode.\n","    model.eval()\n","    # We do not need to maintain intermediate activations while testing.\n","    accs = []\n","    with torch.no_grad():\n","        \n","        # Loop over test data.\n","        for features, target in data_loader:\n","          \n","            # Forward pass.\n","            output = model(features.to(device))\n","            \n","            # Get the label corresponding to the highest predicted probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            \n","            # Count number of correct predictions.\n","            correct = pred.cpu().eq(target.view_as(pred)).sum().item()\n","            total = pred.shape[0]\n","            accs.append(correct/total)\n","\n","    # Print test accuracy.\n","    percent = 100. * np.mean(accs)\n","    st = np.std(accs)\n","    return percent, st\n","\n","def train(model, criterion, data_loader, test_data_loader, optimizer, num_epochs, filename):\n","    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n","    \n","    # Make sure model is in training mode.\n","    model.train()\n","    \n","    # Move model to the device (CPU or GPU).\n","    model.to(device)\n","    \n","    # Exponential moving average of the loss.\n","    ema_loss = None\n","    \n","    best_acc = 0\n","\n","    print('----- Training Loop -----')\n","    # Loop over epochs.\n","    for epoch in range(num_epochs):\n","        \n","        # Loop over data.\n","        for batch_idx, (features, target) in enumerate(data_loader):\n","\n","            # Forward pass.\n","            output = model(features.to(device))\n","            loss = criterion(output.to(device), target.to(device))\n","\n","            # Backward pass.\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # NOTE: It is important to call .item() on the loss before summing.\n","            if ema_loss is None:\n","                ema_loss = loss.item()\n","            else:\n","                ema_loss += (loss.item() - ema_loss) * 0.01 \n","\n","        # Print out progress the end of epoch.\n","        print('----- Model Evaluation -----')\n","        print('Epoch: {}/{} \\tTrain Loss: {:.6f}'.format(epoch+1,num_epochs, ema_loss))\n","        train_a, train_st = test(model,data_loader)\n","        test_a, test_st = test(model,test_data_loader)\n","        print(f'Train accuracy: ({train_a:.2f}%) with std:({train_st:.2f})')\n","        print(f'Test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n","        if test_a > best_acc:\n","            best_acc = test_a\n","            torch.save(model.state_dict(), filename+\".pth\")\n","            \n","    checkpoint = torch.load(filename+\".pth\")\n","    model.load_state_dict(checkpoint)\n","    print(\"------\")\n","    test_a, test_st = test(model,test_data_loader)\n","    print(f'Final test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n","    \n","    return model\n","    \n","\n","def generate_predictions(model,data_loader):\n","    model.eval()\n","    preds=[]\n","    idx=[]\n","\n","    print('----- MAKING PREDICTIONS -----')\n","    # We do not need to maintain intermediate activations while testing.\n","    with torch.no_grad():\n","        \n","        # Loop over test data.\n","        for features, indices in data_loader:\n","            \n","            # Forward pass.\n","            output = model(features.to(device))\n","            \n","            # Get the label corresponding to the highest predicted probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            for p,ind in zip(pred,indices):\n","                idx.append(ind)\n","                preds.append(p.item())\n","\n","    return preds,idx\n","\n","def map_to_classes(n):\n","    return train_data.classes[n]"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Function for pretrained model. Here, resnet was used"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.566978Z","iopub.status.busy":"2022-04-13T12:16:33.566444Z","iopub.status.idle":"2022-04-13T12:16:33.577323Z","shell.execute_reply":"2022-04-13T12:16:33.576551Z","shell.execute_reply.started":"2022-04-13T12:16:33.566850Z"},"trusted":true},"outputs":[],"source":["def get_resnext(model_name):\n","    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n","    model.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n","    model.last_linear = nn.Linear(in_features=2048, out_features=5, bias=True)\n","\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n","\n","    return model, criterion, optimizer\n","\n","def get_eff_net(model_name, dim=1792):\n","    model = EfficientNet.from_pretrained(model_name)\n","    model._fc = nn.Linear(in_features=dim, out_features=5, bias=True)\n","    \n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n","    \n","    return model, criterion, optimizer"]},{"cell_type":"markdown","metadata":{},"source":["## Train and predict"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T12:16:33.578868Z","iopub.status.busy":"2022-04-13T12:16:33.578477Z","iopub.status.idle":"2022-04-13T14:47:42.790738Z","shell.execute_reply":"2022-04-13T14:47:42.789942Z","shell.execute_reply.started":"2022-04-13T12:16:33.578833Z"},"trusted":true},"outputs":[],"source":["preds = []\n","model1, criterion, optimizer = get_resnext(MODEL_NAME1)\n","\n","model1 = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS1, filename=\"resnext\")\n","\n","# tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(DIM_TEST_2,DIM_TEST_2))\n","predictions, _ = generate_predictions(model1,test_loader)\n","# predictions, _ = generate_predictions(tta_model,test_loader)\n","preds.append(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["## Compute the mean for prediction"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T14:47:42.792425Z","iopub.status.busy":"2022-04-13T14:47:42.792186Z","iopub.status.idle":"2022-04-13T14:47:42.799385Z","shell.execute_reply":"2022-04-13T14:47:42.798569Z","shell.execute_reply.started":"2022-04-13T14:47:42.792391Z"},"trusted":true},"outputs":[],"source":["final_predictions = np.mean(preds,axis=0)\n","final_predictions.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Create the dataframe for saving the prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T14:47:42.802162Z","iopub.status.busy":"2022-04-13T14:47:42.801567Z","iopub.status.idle":"2022-04-13T14:47:42.822167Z","shell.execute_reply":"2022-04-13T14:47:42.821534Z","shell.execute_reply.started":"2022-04-13T14:47:42.802126Z"},"trusted":true},"outputs":[],"source":["ss = pd.DataFrame({\n","    \"Category\": final_predictions,\n","    \"Id\": test_data.indices\n","})\n","ss.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Save the prediction"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T14:47:42.840303Z","iopub.status.busy":"2022-04-13T14:47:42.839727Z","iopub.status.idle":"2022-04-13T14:47:42.854021Z","shell.execute_reply":"2022-04-13T14:47:42.853119Z","shell.execute_reply.started":"2022-04-13T14:47:42.840264Z"},"trusted":true},"outputs":[],"source":["ss[\"Category\"] = predictions\n","ss[\"Category\"] = ss[\"Category\"].apply(map_to_classes)\n","ss.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Save the model to CSV"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-04-13T15:04:53.125322Z","iopub.status.busy":"2022-04-13T15:04:53.125082Z","iopub.status.idle":"2022-04-13T15:04:53.139823Z","shell.execute_reply":"2022-04-13T15:04:53.139187Z","shell.execute_reply.started":"2022-04-13T15:04:53.125293Z"},"trusted":true},"outputs":[],"source":["ss.to_csv(\"gasana_annine.csv\",index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
